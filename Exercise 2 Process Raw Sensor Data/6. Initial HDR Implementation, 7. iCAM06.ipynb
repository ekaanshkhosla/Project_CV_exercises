{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98a7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10951d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = rawpy.imread(\"02.CR3\")\n",
    "array = np.array(raw.raw_image_visible)\n",
    "array = array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd6a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1131, 1930, 1100, ...,  685,  607,  675],\n",
       "       [1920, 1604, 1836, ...,  636,  669,  638],\n",
       "       [1139, 1851, 1124, ...,  704,  599,  662],\n",
       "       ...,\n",
       "       [1393, 1178, 1380, ...,  681,  804,  695],\n",
       "       [ 889, 1345,  940, ...,  752,  645,  791],\n",
       "       [1347, 1155, 1373, ...,  682,  766,  684]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53310cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 522)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.max(), array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e5b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rawpy\n",
    "import numpy as np\n",
    "\n",
    "# File paths for your CR3 files\n",
    "cr3_files = [\"00.CR3\", \"01.CR3\", \"02.CR3\", \"03.CR3\",\"04.CR3\", \"05.CR3\",\"06.CR3\", \"07.CR3\",\"08.CR3\", \"09.CR3\", \"10.CR3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537ecd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.CR3',\n",
       " '02.CR3',\n",
       " '03.CR3',\n",
       " '04.CR3',\n",
       " '05.CR3',\n",
       " '06.CR3',\n",
       " '07.CR3',\n",
       " '08.CR3',\n",
       " '09.CR3',\n",
       " '10.CR3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr3_files[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3335b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadf3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = rawpy.imread(\"00.CR3\")\n",
    "h = np.array(raw.raw_image_visible).astype(np.int64)\n",
    "\n",
    "k=1\n",
    "for file in cr3_files[1:]:\n",
    "    raw = rawpy.imread(file)\n",
    "    i = np.array(raw.raw_image_visible).astype(np.int64)\n",
    "    i = np.array(i) * (2**k)\n",
    "    t = 0.8 * h.max()\n",
    "    mask = h > t\n",
    "    h[mask] = i[mask]\n",
    "    k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ec9dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4660, 6984)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15dd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e623948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"HDR_original.png\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a638f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ccae4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78ecc8",
   "metadata": {},
   "source": [
    "### Apply the demosaicing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4758878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1327692d4e9a491880d25de09722ff7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def bilinear_demosaicing(raw_data):\n",
    "    # Assuming raw_data is a numpy array of the RAW image data\n",
    "\n",
    "    # Height and width of the raw image\n",
    "    height, width = raw_data.shape\n",
    "\n",
    "    # Create an empty image for the demosaiced output\n",
    "    # This will be a 3-channel image for the RGB color space\n",
    "    demosaiced_img = np.zeros((height, width, 3), dtype=np.int64)\n",
    "\n",
    "    # Bilinear demosaicing algorithm\n",
    "    for row in tqdm(range(1, height - 1)):\n",
    "        for col in range(1, width - 1):\n",
    "            if (row % 2 == 1) and (col % 2 == 1):  # Blue pixel\n",
    "                demosaiced_img[row, col, 0] = raw_data[row, col]  # Blue\n",
    "                demosaiced_img[row, col, 1] = (raw_data[row, col - 1] + raw_data[row, col + 1] +\n",
    "                                               raw_data[row - 1, col] + raw_data[row + 1, col]) // 4  # Green\n",
    "                demosaiced_img[row, col, 2] = (raw_data[row - 1, col - 1] + raw_data[row - 1, col + 1] +\n",
    "                                               raw_data[row + 1, col - 1] + raw_data[row + 1, col + 1]) // 4  # Red\n",
    "            elif (row % 2 == 0) and (col % 2 == 0):  # Red pixel\n",
    "                demosaiced_img[row, col, 0] = (raw_data[row - 1, col - 1] + raw_data[row - 1, col + 1] +\n",
    "                                               raw_data[row + 1, col - 1] + raw_data[row + 1, col + 1]) // 4  # Blue\n",
    "                demosaiced_img[row, col, 1] = (raw_data[row, col - 1] + raw_data[row, col + 1] +\n",
    "                                               raw_data[row - 1, col] + raw_data[row + 1, col]) // 4  # Green\n",
    "                demosaiced_img[row, col, 2] = raw_data[row, col]  # Red\n",
    "            else:  # Green pixel\n",
    "                demosaiced_img[row, col, 1] = raw_data[row, col]  # Green\n",
    "                if row % 2 == 0:\n",
    "                    demosaiced_img[row, col, 0] = (raw_data[row - 1, col] + raw_data[row + 1, col]) // 2  # Blue\n",
    "                    demosaiced_img[row, col, 2] = (raw_data[row, col - 1] + raw_data[row, col + 1]) // 2  # Red\n",
    "                     \n",
    "                else:\n",
    "                    demosaiced_img[row, col, 0] = (raw_data[row, col - 1] + raw_data[row, col + 1]) // 2  # Blue\n",
    "                    demosaiced_img[row, col, 2] = (raw_data[row - 1, col] + raw_data[row + 1, col]) // 2  # Red\n",
    "\n",
    "\n",
    "    return demosaiced_img\n",
    "\n",
    "\n",
    "demosaiced_image = bilinear_demosaicing(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "436f7d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"HDR_demosaiced_image.png\", demosaiced_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed571148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0, 3014, 3026, ...,  888,  888,    0],\n",
       "       [   0, 3027, 3063, ...,  879,  882,    0],\n",
       "       ...,\n",
       "       [   0, 2171, 2213, ..., 1088, 1098,    0],\n",
       "       [   0, 2125, 2145, ..., 1050, 1082,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "099dd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demosaiced_image = demosaiced_image[1:-1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b83b371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3014, 3026, 3028, ...,  888,  888,  888],\n",
       "       [3027, 3063, 3050, ...,  876,  879,  882],\n",
       "       [3020, 3044, 3052, ...,  883,  877,  870],\n",
       "       ...,\n",
       "       [2217, 2281, 2300, ..., 1138, 1126, 1114],\n",
       "       [2171, 2213, 2263, ..., 1078, 1088, 1098],\n",
       "       [2125, 2145, 2226, ..., 1019, 1050, 1082]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc520eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0d4547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008064"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b1f2e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658, 6982, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6d6de",
   "metadata": {},
   "source": [
    "### Applying White balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9d41eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_white_balance(img):\n",
    "    # Calculate the average color of each RGB channel\n",
    "    avg_r = np.mean(img[:,:,2])\n",
    "    avg_g = np.mean(img[:,:,1])\n",
    "    avg_b = np.mean(img[:,:,0])\n",
    "    # Calculate the overall average color\n",
    "    avg_gray = (avg_r + avg_g + avg_b) / 3\n",
    "\n",
    "    # Scale each channel\n",
    "    img[:,:,2] = (img[:,:,2] / avg_r) * avg_gray\n",
    "    img[:,:,1] = (img[:,:,1] / avg_g) * avg_gray\n",
    "    img[:,:,0] = (img[:,:,0] / avg_b) * avg_gray\n",
    "\n",
    "    return img\n",
    "\n",
    "# Apply white balance\n",
    "white_balanced_image = apply_white_balance(demosaiced_image)\n",
    "\n",
    "# Save the white balanced image\n",
    "white_balanced_output_path = 'HDR_demosaiced_white_balance.png'\n",
    "cv2.imwrite(white_balanced_output_path, white_balanced_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e5da6",
   "metadata": {},
   "source": [
    "### Decreasing the dynamic range by computing the logarithm of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7f7f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.200553887141437, 6.236369590203704)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_image = np.log(white_balanced_image)\n",
    "\n",
    "# Checking the new maximum and minimum values in the transformed image\n",
    "new_max = log_image.max()\n",
    "new_min = log_image.min()\n",
    "\n",
    "new_max, new_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216cb9e",
   "metadata": {},
   "source": [
    "### Downscaling it to the [0, 255] interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "897f2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_255(image):\n",
    "    # Assuming the image is in some range and you want to scale it to 0-255\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    scaled_image = ((image - min_val) / (max_val - min_val)) * 255\n",
    "    return scaled_image.astype(np.uint8)\n",
    "\n",
    "demosaiced_image = map_to_255(log_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a80ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ca59f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demosaiced_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d28b807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'HDR_demosaiced_image_normalized_white_balance.png'\n",
    "cv2.imwrite(output_path, demosaiced_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4608b",
   "metadata": {},
   "source": [
    "### iCAM06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca0f66a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def icam06_tone_mapping(image, output_range=4):\n",
    "    # Convert image to float\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Calculate input_intensity\n",
    "    input_intensity = (20 * image[:, :, 2] + 40 * image[:, :, 1] + image[:, :, 0]) / 61\n",
    "\n",
    "    # Normalize RGB values\n",
    "    r, g, b = image[:, :, 2] / input_intensity, image[:, :, 1] / input_intensity, image[:, :, 0] / input_intensity\n",
    "\n",
    "    # Compute log_base using bilateral filter\n",
    "    log_base = cv2.bilateralFilter(np.log(input_intensity), d=5, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Calculate log_details\n",
    "    log_details = np.log(input_intensity) - log_base\n",
    "\n",
    "    # Compression calculation\n",
    "    compression = np.log(output_range) / (np.max(log_base) - np.min(log_base))\n",
    "\n",
    "    # Offset calculation\n",
    "    log_offset = -np.max(log_base) * compression\n",
    "\n",
    "    # Calculate output_intensity\n",
    "    output_intensity = np.exp(log_base * compression + log_offset + log_details)\n",
    "\n",
    "    # Apply output intensity to RGB values\n",
    "    processed_image = np.stack([r, g, b], axis=-1) * output_intensity[:, :, None]\n",
    "\n",
    "    # Clip values to [0, 1] and convert to 8-bit format\n",
    "    processed_image = np.clip(processed_image, 0, 1) * 255\n",
    "    return processed_image.astype(np.uint8)\n",
    "\n",
    "result = icam06_tone_mapping(demosaiced_image)\n",
    "\n",
    "white_balanced_output_path = 'HDR_demosaiced_image_normalized_white_balance_ICAM06.png'\n",
    "cv2.imwrite(white_balanced_output_path, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
